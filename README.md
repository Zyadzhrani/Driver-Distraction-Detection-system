# ğŸš— Driver Distraction Detection System

This project presents a real-time embedded system designed to detect driver distractions using advanced computer vision and deep learning techniques. Leveraging the NVIDIA Jetson Nano 4GB, the system continuously monitors the driver's behavior through an RGB-IR camera and identifies key distraction types such as mobile phone usage, talking to passengers, and improper hand placement on the steering wheel. The solution combines efficient object detection with GPIO-based feedback mechanisms, making it suitable for real-world deployment in vehicles.
## ğŸ‘¨â€ğŸ’» Team Members
- Zyad Alzahrani 
- Jawad Maimani 
- Abdullah Alghamdi 

## ğŸ“˜ Project Overview
Driver distraction is a major cause of road accidents. Our system detects four critical types of distractions:

### 1. Using a Mobile Phone
![Using mobile phone](Using_mobile_phone.jpg)

### 2. Talking on the Phone (Left or Right Hand)
![Talking on the phone](Talking_on_the_phone.jpg)

### 3. Talking to Passengers
![Talking to passenger](Talking_to_passenger.jpg)

### 4. Not Holding the Steering Wheel
![Not holding wheel](Not_holding_the_steering_wheel.jpg)

## ğŸ§ª Testing Environment
We tested our system in multiple lighting and setup environments.
Below is a representative comparison:

![Test environment comparison](Figure_Y_combined_square.jpg)

## ğŸ“‘ Example Report
An example PDF report generated by the system:

ğŸ‘‰ [Download Report Example](Report_Example.pdf)

## ğŸ”§ Hardware Components
- Jetson Nano 4GB
- Arducam 1080p RGB-IR Camera
- Push Button (for generating PDF reports)
- Buzzer for alerts
- 12V car power adapter
- Custom 3D printed mounts and case

## ğŸ§  Software & Tools
- YOLOv8s-OBB from Ultralytics
- OpenCV (Image capture and display)
- Shapely (Geometric calculations for OBB)
- Jetson.GPIO for GPIO interaction
- Threading + Subprocess for multitasking
- Python 3.8
- JetPack SDK + PyTorch + CUDA/cuDNN

## ğŸ—‚ï¸ Features
- Real-time image capture every 30 seconds
- YOLOv8s-OBB based object detection with rotated bounding boxes
- Custom distraction analysis logic
- 2-second buzzer alert when a distraction is detected
- Button trigger to generate `PDF_FILE.py` report in a separate thread
- Automatic logging of distraction types and counts
- Deletes captured image after use to save disk space

## ğŸ“¸ Classes Detected
| Class ID | Class Name                     |
|----------|--------------------------------|
| 0        | Talking to Passenger           |
| 1        | Hands                          |
| 3        | Using Mobile Phone             |
| 4        | Steering Wheel                 |
| 6        | Talking on Phone (Left/Right)  |
| 7        | Normal Face                    |


## ğŸ§ª Validation
- Achieved over **91% mAP@0.5**
- Successfully deployed on Jetson Nano for real-time performance
- Robust under both day and night conditions using RGB + IR camera




## âš™ï¸ Future Work
- Expand distraction classes (e.g., eating, drowsiness)
- Add dashboard for remote fleet management
- Integrate haptic or visual alerts
- Optimize for Jetson Orin Nano

---

## ğŸ“œ License
This project is part of the EE 499 Senior Design Course at King Abdulaziz University. Use is permitted for educational and non-commercial purposes only.
